{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/miniconda/envs/yz_langseg/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Python 3.11.4\n"
     ]
    }
   ],
   "source": [
    "# streamlit run lseg_app.py -- --weights=\"/mnt/g/Datasets/ADEChallengeData2016/demo_e200.ckpt\" --data-path=\"/mnt/g/Datasets/ADEChallengeData2016/\"\n",
    "\n",
    "\n",
    "# /home/yilu/miniconda3/envs/langseg/lib/python3.11/site-packages/encoding/nn/__init__.py\n",
    "\n",
    "# https://github.com/zhanghang1989/PyTorch-Encoding/compare/master...johndavidbustard:PyTorch-Encoding:master\n",
    "# tried:\n",
    "# https://github.com/krrish94/PyTorch-Encoding/archive/refs/heads/master.zip\n",
    "# \n",
    "# https://github.com/Zacchaeus00/PyTorch-Encoding/archive/refs/heads/master.zip\n",
    "# from encoding import gpu\n",
    "\n",
    "!python --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gradient_clip_val', 'callbacks', 'overfit_batches', 'gradient_clip_algorithm', 'enable_checkpointing', 'min_epochs', 'check_val_every_n_epoch', 'plugins', 'benchmark', 'max_steps', 'fast_dev_run', 'use_distributed_sampler', 'detect_anomaly', 'barebones', 'reload_dataloaders_every_n_epochs', 'num_sanity_val_steps', 'sync_batchnorm', 'logger', 'max_time', 'limit_predict_batches', 'inference_mode', 'devices', 'num_nodes', 'max_epochs', 'log_every_n_steps', 'enable_model_summary', 'strategy', 'default_root_dir', 'val_check_interval', 'limit_test_batches', 'accelerator', 'precision', 'limit_val_batches', 'accumulate_grad_batches', 'enable_progress_bar', 'profiler', 'deterministic', 'min_steps', 'limit_train_batches'}\n",
      "{'num_nodes': 1, 'accumulate_grad_batches': 2, 'max_epochs': 240, 'accelerator': 'ddp', 'benchmark': True, 'sync_batchnorm': True, 'callbacks': [], 'logger': []}\n"
     ]
    }
   ],
   "source": [
    "# !python --version\n",
    "import inspect\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "# Extract the set of accepted arguments from the Trainer's signature\n",
    "accepted_args = set(inspect.signature(Trainer).parameters.keys())\n",
    "print(accepted_args)\n",
    "\n",
    "trainer_args = {'num_nodes': 1, 'exp_name': 'lseg_ade20k_l16', 'dry_run': False, 'no_resume': False, 'accumulate_grad_batches': 2, \n",
    "                'max_epochs': 240, 'project_name': 'lightseg', 'data_path': '../datasets', 'dataset': 'ade20k', 'batch_size': 1, \n",
    "                'base_lr': 0.004, 'momentum': 0.9, 'weight_decay': 0.0001, 'aux': False, 'aux_weight': 0.2, 'se_loss': False, 'se_weight': 0.2, \n",
    "                'midasproto': False, 'ignore_index': -1, 'augment': False, 'backbone': 'clip_vitl16_384', 'num_features': 256, 'dropout': 0.1, \n",
    "                'finetune_weights': None, 'no_scaleinv': False, 'no_batchnorm': False, 'widehead': True, 'widehead_hr': False, 'arch_option': 0, \n",
    "                'block_depth': 0, 'activation': 'lrelu', 'gpus': -1, 'accelerator': 'ddp', 'benchmark': True, 'resume_from_checkpoint': None, \n",
    "                'version': 0, 'sync_batchnorm': True, 'callbacks': [], 'wandb_id': '9r6y3ocp', 'logger': []}\n",
    "\n",
    "# Extract the set of keys from trainer_args\n",
    "provided_args = set(trainer_args.keys())\n",
    "\n",
    "# Find unexpected keywords\n",
    "unexpected_args = provided_args - accepted_args\n",
    "\n",
    "# Remove unexpected keywords from trainer_args\n",
    "for arg in unexpected_args:\n",
    "    trainer_args.pop(arg, None)\n",
    "\n",
    "print(trainer_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['coco', 'ade20k', 'pascal_voc', 'pascal_aug', 'pcontext', 'citys']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_datase' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 24\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdataset \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m not found\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlist\u001b[39m(encoding_datasets\u001b[39m.\u001b[39mkeys()) )\n\u001b[0;32m---> 24\u001b[0m get_datase(\u001b[39m'\u001b[39m\u001b[39made20k\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_datase' is not defined"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "import itertools\n",
    "import functools\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as torch_transforms\n",
    "import encoding.datasets as enc_ds\n",
    "\n",
    "encoding_datasets = {\n",
    "    x: functools.partial(enc_ds.get_dataset, x)\n",
    "    for x in [\"coco\", \"ade20k\", \"pascal_voc\", \"pascal_aug\", \"pcontext\", \"citys\"]\n",
    "}\n",
    "\n",
    "\n",
    "def get_dataset(name, **kwargs):\n",
    "    if name in encoding_datasets:\n",
    "        return encoding_datasets[name.lower()](**kwargs)\n",
    "    assert False, f\"dataset {name} not found\"\n",
    "\n",
    "\n",
    "print(list(encoding_datasets.keys()) )\n",
    "get_dataset('ade20k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wall', 'building', 'sky', 'floor', 'tree', 'ceiling', 'road', 'bed', 'windowpane', 'grass', 'cabinet', 'sidewalk', 'person', 'earth', 'door', 'table', 'mountain', 'plant', 'curtain', 'chair', 'car', 'water', 'painting', 'sofa', 'shelf', 'house', 'sea', 'mirror', 'rug', 'field', 'armchair', 'seat', 'fence', 'desk', 'rock', 'wardrobe', 'lamp', 'bathtub', 'railing', 'cushion', 'base', 'box', 'column', 'signboard', 'chest', 'counter', 'sand', 'sink', 'skyscraper', 'fireplace', 'refrigerator', 'grandstand', 'path', 'stairs', 'runway', 'case', 'pool', 'pillow', 'screen', 'stairway', 'river', 'bridge', 'bookcase', 'blind', 'coffee', 'toilet', 'flower', 'book', 'hill', 'bench', 'countertop', 'stove', 'palm', 'kitchen', 'computer', 'swivel', 'boat', 'bar', 'arcade', 'hovel', 'bus', 'towel', 'light', 'truck', 'tower', 'chandelier', 'awning', 'streetlight', 'booth', 'television', 'airplane', 'dirt', 'apparel', 'pole', 'land', 'bannister', 'escalator', 'ottoman', 'bottle', 'buffet', 'poster', 'stage', 'van', 'ship', 'fountain', 'conveyer', 'canopy', 'washer', 'plaything', 'swimming', 'stool', 'barrel', 'basket', 'waterfall', 'tent', 'bag', 'minibike', 'cradle', 'oven', 'ball', 'food', 'step', 'tank', 'trade', 'microwave', 'pot', 'animal', 'bicycle', 'lake', 'dishwasher', 'screen', 'blanket', 'sculpture', 'hood', 'sconce', 'vase', 'traffic', 'tray', 'ashcan', 'fan', 'pier', 'crt', 'plate', 'monitor', 'bulletin', 'shower', 'radiator', 'glass', 'clock', 'flag']\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "labels = []\n",
    "path = 'label_files/ade20k_objectInfo150.txt'\n",
    "assert os.path.exists(path), '*** Error : {} not exist !!!'.format(path)\n",
    "f = open(path, 'r') \n",
    "lines = f.readlines()      \n",
    "for line in lines: \n",
    "    label = line.strip().split(',')[-1].split(';')[0]\n",
    "    labels.append(label)\n",
    "f.close()\n",
    "labels = labels[1:]\n",
    "print(labels)\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "./checkpoints/lseg_ade20k_l16/version_0/checkpoints//last.ckpt 0\n"
     ]
    }
   ],
   "source": [
    "import pathlib, os\n",
    "from glob import glob\n",
    "def get_latest_version(folder):\n",
    "    versions = [\n",
    "        int(pathlib.PurePath(path).name.split(\"_\")[-1])\n",
    "        for path in glob(f\"{folder}/version_*/\")\n",
    "    ]\n",
    "\n",
    "    if len(versions) == 0:\n",
    "        return None\n",
    "\n",
    "    versions.sort()\n",
    "    return versions[-1]\n",
    "\n",
    "version = get_latest_version(f\"./checkpoints/lseg_ade20k_l16\")\n",
    "print(version)\n",
    "exp_name = 'lseg_ade20k_l16'\n",
    "\n",
    "def get_latest_checkpoint(exp_name, version):\n",
    "    while version > -1:\n",
    "        folder = f\"./checkpoints/{exp_name}/version_{version}/checkpoints/\"\n",
    "\n",
    "        latest = f\"{folder}/last.ckpt\"\n",
    "        if os.path.exists(latest):\n",
    "            return latest, version\n",
    "\n",
    "        chkpts = glob(f\"{folder}/epoch=*.ckpt\")\n",
    "\n",
    "        if len(chkpts) > 0:\n",
    "            break\n",
    "\n",
    "        version -= 1\n",
    "\n",
    "    if len(chkpts) == 0:\n",
    "        return None, None\n",
    "\n",
    "    latest = max(chkpts, key=os.path.getctime)\n",
    "\n",
    "    return latest, version\n",
    "\n",
    "latest, version = get_latest_checkpoint(exp_name, version)\n",
    "print(latest, version)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langseg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
